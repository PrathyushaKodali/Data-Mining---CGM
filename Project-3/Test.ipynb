{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the test file name/pathproj3_test.csv\n",
      "Entered file path proj3_test.csv\n",
      "(51, 8)\n",
      "(51, 9)\n",
      "(51, 13)\n"
     ]
    }
   ],
   "source": [
    "# importing the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "import statistics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_validate,train_test_split,StratifiedKFold,KFold\n",
    "import pickle\n",
    "\n",
    "\n",
    "def DataPreProcessing(CGM_Data):\n",
    "    no_of_rows=CGM_Data.shape[0]\n",
    "    no_of_columns = CGM_Data.shape[1]\n",
    "    CGM_Data.dropna(axis=0, how='all', thresh=no_of_columns/4, subset=None, inplace=True)\n",
    "    CGM_Data.dropna(axis=1, how='all', thresh=no_of_rows/4, subset=None, inplace=True)\n",
    "    CGM_Data.interpolate(axis=0, method ='linear', limit_direction ='forward', inplace=True)\n",
    "    #CGM_Data.bfill(axis=1,inplace=True)\n",
    "    return CGM_Data\n",
    "\n",
    "\n",
    "def ExtractFeatures(CGM_Data):\n",
    "    \n",
    "    Feature_Matrix = pd.DataFrame() \n",
    "\n",
    "    # Feature 1 - Fast Fourier Transform\n",
    "    FFT = pd.DataFrame()\n",
    "    def calculate_fft_vals(series):\n",
    "        FFT_abs = abs(fft(series))\n",
    "        FFT_abs.sort()\n",
    "        return np.flip(FFT_abs)[0:8]\n",
    "\n",
    "    FFT['FFT_vals'] = CGM_Data.apply(lambda series: calculate_fft_vals(series), axis=1)\n",
    "    FFT_Vals= pd.DataFrame(FFT.FFT_vals.tolist(), columns=['FFT1', 'FFT2', 'FFT3', 'FFT4', 'FFT5', 'FFT6', 'FFT7','FFT8'],index=FFT.FFT_vals.index)\n",
    "    Feature_Matrix = pd.concat([Feature_Matrix,FFT_Vals],axis=1)\n",
    "    \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    \n",
    "    # Feature 2 - Max of CGM Velocity \n",
    "    \n",
    "    Velocity_Data = pd.DataFrame()\n",
    "    win_size=6\n",
    "    total_vals=CGM_Data.shape[1]-win_size\n",
    "\n",
    "    for index in range(0, total_vals):\n",
    "        dv = CGM_Data.iloc[:, index + win_size] - CGM_Data.iloc[:, index]\n",
    "        Velocity_Data['vel'+str(index)] = dv\n",
    "\n",
    "    Feature_Matrix['Max CGM Vel']=Velocity_Data.max(axis = 1,skipna=True)\n",
    "    \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "        \n",
    "    # Feature 3 - polyfit   \n",
    "    def calculate_polyfit(series,degree=3):\n",
    "        row_arr = np.array(series.index)\n",
    "        return np.polyfit(row_arr, series, degree)\n",
    "    \n",
    "    Polyfit_vals = CGM_Data.apply(calculate_polyfit,axis=1,result_type='expand')\n",
    "    Feature_Matrix = pd.concat([Feature_Matrix,Polyfit_vals],axis=1)\n",
    "    \n",
    "    print(Feature_Matrix.shape)\n",
    "     \n",
    " \n",
    "    return Feature_Matrix\n",
    "\n",
    "\n",
    "def predit_cluster_labels():\n",
    "\n",
    "    kmeans_handler = open(\"KMeans.model\",\"rb\")\n",
    "    kmeans_labels = pickle.load(kmeans_handler)\n",
    "    pd.DataFrame(kmeans_labels.predict(X_principal)).to_csv(\"KMeans_output.csv\",index=False,header=False)\n",
    "    kmeans_handler.close()\n",
    "\n",
    "    dbscan_handler = open(\"DBSCAN.model\",\"rb\")\n",
    "    dbscan_labels = pickle.load(dbscan_handler)\n",
    "    pd.DataFrame(dbscan_labels.predict(X_principal)).to_csv(\"DBScan_output.csv\",index=False,header=False)\n",
    "    dbscan_handler.close()\n",
    "\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    \n",
    "    column_names = [i for i in range(0,31)]\n",
    "    input_file_path = input(\"Enter the test file name/path\")\n",
    "    print(\"Entered file path\",input_file_path)\n",
    "    Test_Data = pd.read_csv(input_file_path,names=column_names)\n",
    "    \n",
    "    # Data Preprocessing\n",
    "    Test_Data_Pre = DataPreProcessing(Test_Data)\n",
    "    \n",
    "    #Extract Features\n",
    "    Test_Data_Features = ExtractFeatures(Test_Data_Pre)\n",
    "    \n",
    "    # Standardize feature matrix\n",
    "    Feature_Matrix_std  = StandardScaler().fit_transform(Test_Data_Features)\n",
    "    \n",
    "    # Normalize the data so that the data follows a Gaussian distribution\n",
    "    Feature_Matrix_norm = normalize(Feature_Matrix_std)\n",
    "    Feature_Matrix_norm = pd.DataFrame(Feature_Matrix_norm)\n",
    "    \n",
    "    # Do PCA\n",
    "    pca=PCA(n_components=2)\n",
    "    X_principal = pca.fit_transform(Feature_Matrix_norm)\n",
    "    X_principal = pd.DataFrame(X_principal)\n",
    "    X_principal.columns = ['PCA1','PCA2']\n",
    "    \n",
    "    # Predict cluster labels\n",
    "    predit_cluster_labels()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
