{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate,train_test_split,StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "def DataPreProcessing(CGM_Data):\n",
    "    no_of_rows=CGM_Data.shape[0]\n",
    "    no_of_columns = CGM_Data.shape[1]\n",
    "    CGM_Data.dropna(axis=0, how='all', thresh=no_of_columns/4, subset=None, inplace=True)\n",
    "    CGM_Data.dropna(axis=1, how='all', thresh=no_of_rows/4, subset=None, inplace=True)\n",
    "    CGM_Data.interpolate(axis=0, method ='linear', limit_direction ='forward', inplace=True)\n",
    "    CGM_Data.bfill(axis=1,inplace=True)\n",
    "    return CGM_Data\n",
    "\n",
    "def ExtractFeatures(CGM_Data):\n",
    "    \n",
    "    Feature_Matrix = pd.DataFrame() \n",
    "    \n",
    "    # Feature 1 - Windowed Mean (for 30 min interval)\n",
    "    win_size=6\n",
    "    total_vals = CGM_Data.shape[1]-win_size\n",
    "    for index in range(0, total_vals, win_size):\n",
    "        dm = CGM_Data.iloc[:, index:index + win_size].mean(axis=1)\n",
    "        Feature_Matrix['Mean ' + str(index)] = dm\n",
    "\n",
    "    print(Feature_Matrix.shape)\n",
    "\n",
    "    \n",
    "    # Feature 2 - Windowed Standard Deviation (for 30 min interval)\n",
    "    win_size=6\n",
    "    total_vals = CGM_Data.shape[1]-win_size\n",
    "    for index in range(0, total_vals, win_size):\n",
    "        dstd = CGM_Data.iloc[:, index:index + win_size].std(axis=1)\n",
    "        Feature_Matrix['Std_deviation ' + str(index)] = dstd\n",
    "        \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    \n",
    "    # Feature 3 - Fast Fourier Transform\n",
    "    FFT = pd.DataFrame()\n",
    "    def calculate_fft_vals(series):\n",
    "        FFT_abs = abs(fft(series))\n",
    "        FFT_abs.sort()\n",
    "        return np.flip(FFT_abs)[0:8]\n",
    "\n",
    "    FFT['FFT_vals'] = CGM_Data.apply(lambda series: calculate_fft_vals(series), axis=1)\n",
    "    FFT_Vals= pd.DataFrame(FFT.FFT_vals.tolist(), columns=['FFT1', 'FFT2', 'FFT3', 'FFT4', 'FFT5', 'FFT6', 'FFT7','FFT8'],index=FFT.FFT_vals.index)\n",
    "    Feature_Matrix = pd.concat([Feature_Matrix,FFT_Vals],axis=1)\n",
    "    \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    \n",
    "    # Feature 4 - Max of CGM Velocity \n",
    "    \n",
    "    Velocity_Data = pd.DataFrame()\n",
    "    win_size=6\n",
    "    total_vals=CGM_Data.shape[1]-win_size\n",
    "\n",
    "    for index in range(0, total_vals):\n",
    "        dv = CGM_Data.iloc[:, index + win_size] - CGM_Data.iloc[:, index]\n",
    "        Velocity_Data['vel'+str(index)] = dv\n",
    "\n",
    "    Feature_Matrix['Max CGM Vel']=Velocity_Data.max(axis = 1,skipna=True)\n",
    "    \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    \n",
    "    # Feature 5 - Skewness\n",
    "    def calculate_skewness(series):\n",
    "        series_counts = series.value_counts()\n",
    "        skewness_vals = skew(series_counts)\n",
    "        return skewness_vals\n",
    "\n",
    "    Feature_Matrix['skewness'] = CGM_Data.apply(lambda row: calculate_skewness(row), axis=1)\n",
    "    \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    \n",
    "    # Feature 6 - polyfit   \n",
    "    def calculate_polyfit(series,degree=3):\n",
    "        row_arr = np.array(series.index)\n",
    "        return np.polyfit(row_arr, series, degree)\n",
    "    \n",
    "    Polyfit_vals = CGM_Data.apply(calculate_polyfit,axis=1,result_type='expand')\n",
    "    Feature_Matrix = pd.concat([Feature_Matrix,Polyfit_vals],axis=1)\n",
    "    \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    return Feature_Matrix\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(245, 4)\n",
      "(245, 8)\n",
      "(245, 16)\n",
      "(245, 17)\n",
      "(245, 18)\n",
      "(245, 22)\n",
      "(242, 4)\n",
      "(242, 8)\n",
      "(242, 16)\n",
      "(242, 17)\n",
      "(242, 18)\n",
      "(242, 22)\n",
      "--------KNN MODELS-----------\n",
      "For KNN with K value:1\n",
      "Accuracy: 0.5913528297917104 Precision: 0.5918900883805127 Recall: 0.6000000000000001 F1 Measure: 0.5953513632965299\n",
      "For KNN with K value:2\n",
      "Accuracy: 0.5667367978119082 Precision: 0.6126617038875103 Recall: 0.3714285714285714 F1 Measure: 0.46054934159774075\n",
      "For KNN with K value:3\n",
      "Accuracy: 0.5791289711760993 Precision: 0.577863631825896 Recall: 0.6163265306122448 F1 Measure: 0.5955939607819992\n",
      "For KNN with K value:4\n",
      "Accuracy: 0.5708184304649695 Precision: 0.5946935036151981 Recall: 0.4612244897959184 F1 Measure: 0.519207695617432\n",
      "For KNN with K value:5\n",
      "Accuracy: 0.5995792131285504 Precision: 0.5994430538172717 Recall: 0.616326530612245 F1 Measure: 0.6073010837959292\n",
      "--------SVM MODEL-----------\n",
      "Accuracy: 0.6571638964864295 Precision: 0.674132909808318 Recall: 0.6244897959183673 F1 Measure: 0.6474579954758881\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    # Meal Data\n",
    "    column_names = [i for i in range(0,31)]\n",
    "    data_file_1 = pd.read_csv(\"mealData1.csv\",names=column_names)\n",
    "    data_file_2 = pd.read_csv(\"mealData2.csv\",names=column_names)\n",
    "    data_file_3 = pd.read_csv(\"mealData3.csv\",names=column_names)\n",
    "    data_file_4 = pd.read_csv(\"mealData4.csv\",names=column_names)\n",
    "    data_file_5 = pd.read_csv(\"mealData5.csv\",names=column_names)\n",
    "    CGM_Data_Meal = pd.concat([data_file_1,data_file_2,data_file_3,data_file_4,data_file_5],axis=0)\n",
    "\n",
    "    # No Meal Data\n",
    "    column_names = [i for i in range(0,31)]\n",
    "    data_file_1 = pd.read_csv(\"Nomeal1.csv\",names=column_names)\n",
    "    data_file_2 = pd.read_csv(\"Nomeal2.csv\",names=column_names)\n",
    "    data_file_3 = pd.read_csv(\"Nomeal3.csv\",names=column_names)\n",
    "    data_file_4 = pd.read_csv(\"Nomeal4.csv\",names=column_names)\n",
    "    data_file_5 = pd.read_csv(\"Nomeal5.csv\",names=column_names)\n",
    "    CGM_Data_No_Meal = pd.concat([data_file_1,data_file_2,data_file_3,data_file_4,data_file_5],axis=0)\n",
    "    \n",
    "    # Data Pre-Processing\n",
    "    Meal_Data = DataPreProcessing(CGM_Data_Meal)\n",
    "    No_Meal_Data = DataPreProcessing(CGM_Data_No_Meal)\n",
    "    \n",
    "    #Extract Features\n",
    "    Meal_Data_Features = ExtractFeatures(Meal_Data) \n",
    "    No_Meal_Data_Features = ExtractFeatures(No_Meal_Data) \n",
    "    \n",
    "    # Merge both Meal and No Meal Data features\n",
    "    Feature_Matrix = pd.concat([Meal_Data_Features,No_Meal_Data_Features]) \n",
    "    \n",
    "    # Standardize feature matrix\n",
    "    Feature_Matrix = StandardScaler().fit_transform(Feature_Matrix)\n",
    "    \n",
    "    #Class labels \n",
    "    Class_labels = np.append(np.ones(len(Meal_Data_Features)),np.zeros(len(No_Meal_Data_Features)))\n",
    "\n",
    "    \n",
    "    # Training KNN Model\n",
    "    \n",
    "    print(\"--------KNN MODELS-----------\")    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(Feature_Matrix, Class_labels, test_size=0.2, random_state=4)\n",
    "    \n",
    "    K = 5 \n",
    "    for n in range(1,K+1):\n",
    "        neighbours = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n",
    "        yhat=neighbours.predict(X_test)\n",
    "        skfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=777 )\n",
    "        scores = cross_validate(neighbours, Feature_Matrix, Class_labels, cv=skfold,\n",
    "                                scoring=('accuracy', 'precision','recall','f1'),\n",
    "                                 return_train_score=True)   \n",
    "        print(\"For KNN with K value:\"+str(n))\n",
    "        print(\"Accuracy:\",scores['test_accuracy'].mean(), \n",
    "              \"Precision:\",scores['test_precision'].mean(),\n",
    "              \"Recall:\",scores['test_recall'].mean(),\n",
    "              \"F1 Measure:\",scores['test_f1'].mean())\n",
    "        neighbours.fit(Feature_Matrix, Class_labels)\n",
    "        handler = open(\"KNN\"+str(n)+\".model\",\"wb\")\n",
    "        pickle.dump(neighbours,handler)\n",
    "        handler.close()\n",
    "       \n",
    "    \n",
    "    #Training SVC model\n",
    "    print(\"--------SVM MODEL-----------\") \n",
    "    svc = SVC(gamma='auto',random_state=777)\n",
    "    skfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=777 )\n",
    "    scores = cross_validate(svc, Feature_Matrix, Class_labels, cv=skfold,\n",
    "                            scoring=('accuracy', 'precision','recall','f1'),\n",
    "                            return_train_score=True)   \n",
    "    print(\"Accuracy:\",scores['test_accuracy'].mean(), \n",
    "          \"Precision:\",scores['test_precision'].mean(),\n",
    "          \"Recall:\",scores['test_recall'].mean(),\n",
    "          \"F1 Measure:\",scores['test_f1'].mean())\n",
    "    svc.fit(Feature_Matrix, Class_labels)\n",
    "    handler = open(\"SVC.model\",\"wb\")\n",
    "    pickle.dump(svc,handler)\n",
    "    handler.close()\n",
    "    \n",
    "    \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
