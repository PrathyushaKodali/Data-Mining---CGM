{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the test file name/pathNomeal1.csv\n",
      "Entered file path Nomeal1.csv\n",
      "(51, 4)\n",
      "(51, 8)\n",
      "(51, 16)\n",
      "(51, 17)\n",
      "(51, 18)\n",
      "(51, 22)\n",
      "------ Predicting class using KNN model--------\n",
      "Generated output for KNN1 in KNN1output.csv\n",
      "Generated output for KNN2 in KNN2output.csv\n",
      "Generated output for KNN3 in KNN3output.csv\n",
      "Generated output for KNN4 in KNN4output.csv\n",
      "Generated output for KNN5 in KNN5output.csv\n",
      "------ Predicting class using SVM model--------\n",
      "Generated output for SVC in SVCoutput.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import fftpack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.model_selection import cross_validate,train_test_split,StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "from scipy.stats import skew\n",
    "\n",
    "def DataPreProcessing(CGM_Data):\n",
    "    no_of_rows=CGM_Data.shape[0]\n",
    "    no_of_columns = CGM_Data.shape[1]\n",
    "    CGM_Data.dropna(axis=0, how='all', thresh=no_of_columns/4, subset=None, inplace=True)\n",
    "    CGM_Data.dropna(axis=1, how='all', thresh=no_of_rows/4, subset=None, inplace=True)\n",
    "    CGM_Data.interpolate(axis=1, method ='linear', limit_direction ='forward', inplace=True)\n",
    "    CGM_Data.bfill(axis=1,inplace=True)\n",
    "    return CGM_Data\n",
    "\n",
    "\n",
    "def ExtractFeatures(CGM_Data):\n",
    "    Feature_Matrix = pd.DataFrame()\n",
    "\n",
    "    # Feature 1 - Windowed Mean (for 30 min interval)\n",
    "    win_size=6\n",
    "    total_vals = CGM_Data.shape[1]-win_size\n",
    "    for index in range(0, total_vals, win_size):\n",
    "        dm = CGM_Data.iloc[:, index:index + win_size].mean(axis=1)\n",
    "        Feature_Matrix['Mean ' + str(index)] = dm\n",
    "\n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    # Feature 2 - Windowed Standard Deviation (for 30 min interval)\n",
    "    win_size=6\n",
    "    total_vals = CGM_Data.shape[1]-win_size\n",
    "    for index in range(0, total_vals, win_size):\n",
    "        dstd = CGM_Data.iloc[:, index:index + win_size].std(axis=1)\n",
    "        Feature_Matrix['Std_deviation ' + str(index)] = dstd\n",
    "        \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    # Feature 3 - Fast Fourier Transform\n",
    "    FFT = pd.DataFrame()\n",
    "    def calculate_fft_vals(series):\n",
    "        FFT_abs = abs(fft(series))\n",
    "        FFT_abs.sort()\n",
    "        return np.flip(FFT_abs)[0:8]\n",
    "\n",
    "    FFT['FFT_vals'] = CGM_Data.apply(lambda series: calculate_fft_vals(series), axis=1)\n",
    "    FFT_Vals= pd.DataFrame(FFT.FFT_vals.tolist(), columns=['FFT1', 'FFT2', 'FFT3', 'FFT4', 'FFT5', 'FFT6', 'FFT7','FFT8'],index=FFT.FFT_vals.index)\n",
    "    Feature_Matrix = pd.concat([Feature_Matrix,FFT_Vals],axis=1)\n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    \n",
    "    # Feature 4 - CGM Velocity \n",
    "    Velocity_Data = pd.DataFrame()\n",
    "    win_size=6\n",
    "    total_vals=CGM_Data.shape[1]-win_size\n",
    "\n",
    "    for index in range(0, total_vals):\n",
    "        dv = CGM_Data.iloc[:, index + win_size] - CGM_Data.iloc[:, index]\n",
    "        Velocity_Data['vel'+str(index)] = dv\n",
    "\n",
    "    Feature_Matrix['Max CGM Vel']=Velocity_Data.max(axis = 1,skipna=True)\n",
    "       \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    \n",
    "    # Feature 5 - Skewness\n",
    "    def calculate_skewness(series):\n",
    "        series_counts = series.value_counts()\n",
    "        skewness_vals = skew(series_counts)\n",
    "        return skewness_vals\n",
    "\n",
    "    Feature_Matrix['skewness'] = CGM_Data.apply(lambda row: calculate_skewness(row), axis=1)\n",
    "    \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    # Feature 6 - polyfit   \n",
    "    def calculate_polyfit(series,degree=3):\n",
    "        row_arr = np.array(series.index)\n",
    "        return np.polyfit(row_arr, series, degree)\n",
    "    \n",
    "    Polyfit_vals = CGM_Data.apply(calculate_polyfit,axis=1,result_type='expand')\n",
    "    Feature_Matrix = pd.concat([Feature_Matrix,Polyfit_vals],axis=1)\n",
    "    \n",
    "    print(Feature_Matrix.shape)\n",
    "    \n",
    "    \n",
    "    return Feature_Matrix\n",
    "\n",
    "\n",
    "def predit_class():\n",
    "    \n",
    "    K=5\n",
    "    print(\"------ Predicting class using KNN model--------\")\n",
    "    for i in range(1,K+1):\n",
    "        handler = open(\"KNN\"+str(i)+\".model\",\"rb\")\n",
    "        model = pickle.load(handler)\n",
    "        pd.DataFrame(model.predict(Feature_Matrix)).to_csv(\"KNN\"+str(i)+\"output.csv\",index=False,header=False)\n",
    "        handler.close()\n",
    "        print(\"Generated output for KNN\"+str(i)+\" in KNN\"+str(i)+\"output.csv\")\n",
    "    \n",
    "\n",
    "    print(\"------ Predicting class using SVM model--------\")\n",
    "    handler = open(\"SVC.model\",\"rb\")\n",
    "    model = pickle.load(handler)\n",
    "    pd.DataFrame(model.predict(Feature_Matrix)).to_csv(\"SVCoutput.csv\",index=False,header=False)\n",
    "    handler.close()\n",
    "    print(\"Generated output for SVC in SVCoutput.csv\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    column_names = [i for i in range(0,31)]\n",
    "    input_file_path = input(\"Enter the test file name/path\")\n",
    "    print(\"Entered file path\",input_file_path)\n",
    "    Test_Data = pd.read_csv(input_file_path,names=column_names)\n",
    "    \n",
    "    # Data Preprocessing\n",
    "    Test_Data_Pre = DataPreProcessing(Test_Data)\n",
    "    \n",
    "    #Extract Features\n",
    "    Test_Data_Features = ExtractFeatures(Test_Data_Pre)\n",
    "    \n",
    "    # Standardize feature matrix\n",
    "    Feature_Matrix  = StandardScaler().fit_transform(Test_Data_Features)\n",
    "    \n",
    "    # Predict class labels\n",
    "    predit_class()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
